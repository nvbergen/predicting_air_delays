{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "766eb4fc-473b-4a0e-ad7e-3d1d0f6e9282",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Predicting Air Delays \n",
    "----\n",
    "\n",
    "Thank you for your review of my code notebook.\n",
    "This notebook's goal is to obtain, modify, clean, and prepare the dataset for exposure on a Machine Learning algorithm.\n",
    "\n",
    "---\n",
    "#### Problem Statement: \n",
    "Both travelers and airlines find delays frustrating and costly. This project attempts to be able to predict the probability of a commercial flight delay for any flight in the United States. \n",
    "\n",
    "---\n",
    "\n",
    "#### MVP:\n",
    "My product will be a small lightweight application run on `streamlit` platform for proof-of-concept where a user can find the probability of their desired flight having a delay, how long the delay may be, and how much will the delay cost the user in _lost time_ at the destination \n",
    "\n",
    "---\n",
    "# Intake, Cleaning, and EDA. \n",
    "\n",
    "The primary challenge in this notebook is managing a large dataset. \n",
    "The next challenge will be to conduct meaningful EDA across the whole dataset. \n",
    "The notebook is structured as follows. \n",
    "1. Imports and set up\n",
    "2. The size and complexity issue. \n",
    "3. Cleaning steps. \n",
    "4. Feature engineering and selection. \n",
    "5. Save the final CSV and discuss next steps. \n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a7a039-e68d-42d2-ae8e-aac54bc196a6",
   "metadata": {},
   "source": [
    "## 1. Set-up\n",
    "----\n",
    "I will be making use of `OS` Library and command line commands from the notebook to join large CSV tables together. \n",
    "The standard set up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1cf4036e-d2dc-4772-ab16-d833e8e69624",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a641813-7982-42c1-9f4f-cc8d94fbbd51",
   "metadata": {},
   "source": [
    " I have 68 CSV files. Each file represents 1 month of flight history from all U.S. Airports. As a result each CSV is approximatley 150mb in size. Loading a few of them into the workspace of the notebook will result in a loss of data due to data exceeding memory capacity on the local machine. \n",
    " <br>\n",
    " <br>\n",
    "The approach will be to manipulate each of the CSV's and join them directly in the command line. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e87f7c0f-bf35-48ac-a29b-bdc9a503cfe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#change the directory from root to where all the files I will join will be\n",
    "os.chdir('/Volumes/lacie/data_ingestion/capstone_hopper')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44cc0827-9b7e-41f8-add9-ff7887813038",
   "metadata": {},
   "source": [
    "### Data Sources\n",
    "---\n",
    "This project attempts gathered delay data from the **Department of Transportation (DOT) Flight Delay reporting Database**. Sadly, there was no public API available to access this data from DOT or from Federal Aviation Administration.\n",
    "\n",
    "Given there was no way to programatically acquire the desired amount of data, I proceeded to utilize the basic public data library tool and download a CSV for one monthly period at a time.  \n",
    "\n",
    "This created a lot of _just **too big** files_ and hence our first unanticipated technical challenge with this project; what do I do? \n",
    "\n",
    "The plan: use the command line to join all the tables. \n",
    "After cleaning see how large the file is. \n",
    "\n",
    "To implement this plan, using `glob` methods and direct command line. \n",
    "\n",
    "\n",
    "---\n",
    "References\n",
    "[Bureau of Transportation Statistics](https://www.transtats.bts.gov/DL_SelectFields.asp?gnoyr_VQ=FGJ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e7b3315-9cc1-4042-80c9-1c1f9ce8ec6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m00_cause_of_delay.csv\u001b[m\u001b[m \u001b[31m30_mar_19.csv\u001b[m\u001b[m         \u001b[31m51_jun_17.csv\u001b[m\u001b[m\n",
      "\u001b[31m10_nov_20.csv\u001b[m\u001b[m         \u001b[31m31_feb_19.csv\u001b[m\u001b[m         \u001b[31m52_may_17.csv\u001b[m\u001b[m\n",
      "\u001b[31m11_oct_20.csv\u001b[m\u001b[m         \u001b[31m32_jan_19.csv\u001b[m\u001b[m         \u001b[31m53_apr_17.csv\u001b[m\u001b[m\n",
      "\u001b[31m12_sep_20.csv\u001b[m\u001b[m         \u001b[31m33_dec_18.csv\u001b[m\u001b[m         \u001b[31m54_mar_17.csv\u001b[m\u001b[m\n",
      "\u001b[31m13_aug_20.csv\u001b[m\u001b[m         \u001b[31m34_nov_18.csv\u001b[m\u001b[m         \u001b[31m55_feb_17.csv\u001b[m\u001b[m\n",
      "\u001b[31m14_jul_20.csv\u001b[m\u001b[m         \u001b[31m35_oct_18.csv\u001b[m\u001b[m         \u001b[31m56_jan_17.csv\u001b[m\u001b[m\n",
      "\u001b[31m15_jun_20.csv\u001b[m\u001b[m         \u001b[31m36_sep_18.csv\u001b[m\u001b[m         \u001b[31m57_dec_16.csv\u001b[m\u001b[m\n",
      "\u001b[31m16_may_20.csv\u001b[m\u001b[m         \u001b[31m37_aug_18.csv\u001b[m\u001b[m         \u001b[31m58_nov_16.csv\u001b[m\u001b[m\n",
      "\u001b[31m17_apr_20.csv\u001b[m\u001b[m         \u001b[31m38_jul_18.csv\u001b[m\u001b[m         \u001b[31m59_oct_16.csv\u001b[m\u001b[m\n",
      "\u001b[31m18_mar_20.csv\u001b[m\u001b[m         \u001b[31m39_jun_18.csv\u001b[m\u001b[m         \u001b[31m5_apr_21.csv\u001b[m\u001b[m\n",
      "\u001b[31m19_feb_20.csv\u001b[m\u001b[m         \u001b[31m3_jun_21.csv\u001b[m\u001b[m          \u001b[31m60_sep_16.csv\u001b[m\u001b[m\n",
      "\u001b[31m1_aug_21.csv\u001b[m\u001b[m          \u001b[31m40_may_18.csv\u001b[m\u001b[m         \u001b[31m61_aug_16.csv\u001b[m\u001b[m\n",
      "\u001b[31m20_jan_20.csv\u001b[m\u001b[m         \u001b[31m41_apr_18.csv\u001b[m\u001b[m         \u001b[31m62_jul_16.csv\u001b[m\u001b[m\n",
      "\u001b[31m21_dec_19.csv\u001b[m\u001b[m         \u001b[31m42_mar_18.csv\u001b[m\u001b[m         \u001b[31m63_jun_16.csv\u001b[m\u001b[m\n",
      "\u001b[31m22_nov_19.csv\u001b[m\u001b[m         \u001b[31m43_feb_18.csv\u001b[m\u001b[m         \u001b[31m64_may_16.csv\u001b[m\u001b[m\n",
      "\u001b[31m23_oct_19.csv\u001b[m\u001b[m         \u001b[31m44_jan_18.csv\u001b[m\u001b[m         \u001b[31m65_apr_16.csv\u001b[m\u001b[m\n",
      "\u001b[31m24_sep_19.csv\u001b[m\u001b[m         \u001b[31m45_dec_17.csv\u001b[m\u001b[m         \u001b[31m66_mar_16.csv\u001b[m\u001b[m\n",
      "\u001b[31m25_aug_19.csv\u001b[m\u001b[m         \u001b[31m46_nov_17.csv\u001b[m\u001b[m         \u001b[31m67_feb_16.csv\u001b[m\u001b[m\n",
      "\u001b[31m26_jul_19.csv\u001b[m\u001b[m         \u001b[31m47_oct_17.csv\u001b[m\u001b[m         \u001b[31m68_jan_16.csv\u001b[m\u001b[m\n",
      "\u001b[31m27_jun_19.csv\u001b[m\u001b[m         \u001b[31m48_sep_17.csv\u001b[m\u001b[m         \u001b[31m6_mar_21.csv\u001b[m\u001b[m\n",
      "\u001b[31m28_may_19.csv\u001b[m\u001b[m         \u001b[31m49_aug_17.csv\u001b[m\u001b[m         \u001b[31m7_feb_21.csv\u001b[m\u001b[m\n",
      "\u001b[31m29_apr_19.csv\u001b[m\u001b[m         \u001b[31m4_may_21.csv\u001b[m\u001b[m          \u001b[31m8_jan_21.csv\u001b[m\u001b[m\n",
      "\u001b[31m2_jul_21.csv\u001b[m\u001b[m          \u001b[31m50_jul_17.csv\u001b[m\u001b[m         \u001b[31m9_dec_20.csv\u001b[m\u001b[m\n"
     ]
    }
   ],
   "source": [
    "#a list of all the files. a total of 6.958GB of unfiltered raw data. \n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0559f5e4-8774-41f1-947a-b9b2c94f70cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#using glob, to locate all file names. \n",
    "file_ext = '.csv'\n",
    "files = [file for file in glob.glob(f'*{file_ext}')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9fbce328-28a8-4086-8f02-8992f4b70bed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['00_cause_of_delay.csv', '1_aug_21.csv', '2_jul_21.csv', '3_jun_21.csv', '4_may_21.csv']\n"
     ]
    }
   ],
   "source": [
    "#the first five in the list to confirm \n",
    "print(files[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb248bc2-7abd-4d55-853f-ee706ccca3a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
