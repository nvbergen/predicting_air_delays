{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "766eb4fc-473b-4a0e-ad7e-3d1d0f6e9282",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Predicting Air Delays \n",
    "----\n",
    "\n",
    "Thank you for your review of my code notebook.\n",
    "This notebook's goal is to obtain, modify, clean, and prepare the dataset for exposure on a Machine Learning algorithm.\n",
    "\n",
    "---\n",
    "#### Problem Statement: \n",
    "Both travelers and airlines find delays frustrating and costly. This project attempts to be able to predict the probability of a commercial flight delay for any flight in the United States. \n",
    "\n",
    "---\n",
    "\n",
    "#### MVP:\n",
    "My product will be a small lightweight application run on `streamlit` platform for proof-of-concept where a user can find the probability of their desired flight having a delay, how long the delay may be, and how much will the delay cost the user in _lost time_ at the destination \n",
    "\n",
    "---\n",
    "# Intake, Cleaning, and EDA. \n",
    "\n",
    "The primary challenge in this notebook is managing a large dataset. \n",
    "The next challenge will be to conduct meaningful EDA across the whole dataset. \n",
    "The notebook is structured as follows. \n",
    "1. Imports and set up\n",
    "2. The size and complexity issue. \n",
    "3. Cleaning steps. \n",
    "4. Feature engineering and selection. \n",
    "5. Save the final CSV and discuss next steps. \n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a7a039-e68d-42d2-ae8e-aac54bc196a6",
   "metadata": {},
   "source": [
    "## 1. Set-up\n",
    "----\n",
    "I will be making use of `OS` Library and command line commands from the notebook to join large CSV tables together. \n",
    "The standard set up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1cf4036e-d2dc-4772-ab16-d833e8e69624",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a641813-7982-42c1-9f4f-cc8d94fbbd51",
   "metadata": {},
   "source": [
    " I have 68 CSV files. Each file represents 1 month of flight history from all U.S. Airports. As a result each CSV is approximatley 150mb in size. Loading a few of them into the workspace of the notebook will result in a loss of data due to data exceeding memory capacity on the local machine. \n",
    " <br>\n",
    " <br>\n",
    "The approach will be to manipulate each of the CSV's and join them directly in the command line. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e87f7c0f-bf35-48ac-a29b-bdc9a503cfe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#change the directory from root to where all the files I will join will be\n",
    "os.chdir('/Volumes/lacie/data_ingestion/capstone_hopper')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44cc0827-9b7e-41f8-add9-ff7887813038",
   "metadata": {},
   "source": [
    "### Data Sources\n",
    "---\n",
    "This project attempts gathered delay data from the **Department of Transportation (DOT) Flight Delay reporting Database**. Sadly, there was no public API available to access this data from DOT or from Federal Aviation Administration.\n",
    "\n",
    "Given there was no way to programatically acquire the desired amount of data, I proceeded to utilize the basic public data library tool and download a CSV for one monthly period at a time.  \n",
    "\n",
    "This created a lot of _just **too big** files_ and hence our first unanticipated technical challenge with this project; what do I do? \n",
    "\n",
    "The plan: use the command line to join all the tables. \n",
    "After cleaning see how large the file is. \n",
    "\n",
    "To implement this plan, using `glob` methods and direct command line. \n",
    "\n",
    "\n",
    "---\n",
    "References<br>\n",
    "[Bureau of Transportation Statistics](https://www.transtats.bts.gov/DL_SelectFields.asp?gnoyr_VQ=FGJ)\n",
    "<br>\n",
    "[GLOB tutorial](https://www.freecodecamp.org/news/how-to-combine-multiple-csv-files-with-8-lines-of-code-265183e0854/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e7b3315-9cc1-4042-80c9-1c1f9ce8ec6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m10_nov_20.csv\u001b[m\u001b[m \u001b[31m23_oct_19.csv\u001b[m\u001b[m \u001b[31m36_sep_18.csv\u001b[m\u001b[m \u001b[31m49_aug_17.csv\u001b[m\u001b[m \u001b[31m61_aug_16.csv\u001b[m\u001b[m\n",
      "\u001b[31m11_oct_20.csv\u001b[m\u001b[m \u001b[31m24_sep_19.csv\u001b[m\u001b[m \u001b[31m37_aug_18.csv\u001b[m\u001b[m \u001b[31m4_may_21.csv\u001b[m\u001b[m  \u001b[31m62_jul_16.csv\u001b[m\u001b[m\n",
      "\u001b[31m12_sep_20.csv\u001b[m\u001b[m \u001b[31m25_aug_19.csv\u001b[m\u001b[m \u001b[31m38_jul_18.csv\u001b[m\u001b[m \u001b[31m50_jul_17.csv\u001b[m\u001b[m \u001b[31m63_jun_16.csv\u001b[m\u001b[m\n",
      "\u001b[31m13_aug_20.csv\u001b[m\u001b[m \u001b[31m26_jul_19.csv\u001b[m\u001b[m \u001b[31m39_jun_18.csv\u001b[m\u001b[m \u001b[31m51_jun_17.csv\u001b[m\u001b[m \u001b[31m64_may_16.csv\u001b[m\u001b[m\n",
      "\u001b[31m14_jul_20.csv\u001b[m\u001b[m \u001b[31m27_jun_19.csv\u001b[m\u001b[m \u001b[31m3_jun_21.csv\u001b[m\u001b[m  \u001b[31m52_may_17.csv\u001b[m\u001b[m \u001b[31m65_apr_16.csv\u001b[m\u001b[m\n",
      "\u001b[31m15_jun_20.csv\u001b[m\u001b[m \u001b[31m28_may_19.csv\u001b[m\u001b[m \u001b[31m40_may_18.csv\u001b[m\u001b[m \u001b[31m53_apr_17.csv\u001b[m\u001b[m \u001b[31m66_mar_16.csv\u001b[m\u001b[m\n",
      "\u001b[31m16_may_20.csv\u001b[m\u001b[m \u001b[31m29_apr_19.csv\u001b[m\u001b[m \u001b[31m41_apr_18.csv\u001b[m\u001b[m \u001b[31m54_mar_17.csv\u001b[m\u001b[m \u001b[31m67_feb_16.csv\u001b[m\u001b[m\n",
      "\u001b[31m17_apr_20.csv\u001b[m\u001b[m \u001b[31m2_jul_21.csv\u001b[m\u001b[m  \u001b[31m42_mar_18.csv\u001b[m\u001b[m \u001b[31m55_feb_17.csv\u001b[m\u001b[m \u001b[31m68_jan_16.csv\u001b[m\u001b[m\n",
      "\u001b[31m18_mar_20.csv\u001b[m\u001b[m \u001b[31m30_mar_19.csv\u001b[m\u001b[m \u001b[31m43_feb_18.csv\u001b[m\u001b[m \u001b[31m56_jan_17.csv\u001b[m\u001b[m \u001b[31m6_mar_21.csv\u001b[m\u001b[m\n",
      "\u001b[31m19_feb_20.csv\u001b[m\u001b[m \u001b[31m31_feb_19.csv\u001b[m\u001b[m \u001b[31m44_jan_18.csv\u001b[m\u001b[m \u001b[31m57_dec_16.csv\u001b[m\u001b[m \u001b[31m7_feb_21.csv\u001b[m\u001b[m\n",
      "\u001b[31m1_aug_21.csv\u001b[m\u001b[m  \u001b[31m32_jan_19.csv\u001b[m\u001b[m \u001b[31m45_dec_17.csv\u001b[m\u001b[m \u001b[31m58_nov_16.csv\u001b[m\u001b[m \u001b[31m8_jan_21.csv\u001b[m\u001b[m\n",
      "\u001b[31m20_jan_20.csv\u001b[m\u001b[m \u001b[31m33_dec_18.csv\u001b[m\u001b[m \u001b[31m46_nov_17.csv\u001b[m\u001b[m \u001b[31m59_oct_16.csv\u001b[m\u001b[m \u001b[31m9_dec_20.csv\u001b[m\u001b[m\n",
      "\u001b[31m21_dec_19.csv\u001b[m\u001b[m \u001b[31m34_nov_18.csv\u001b[m\u001b[m \u001b[31m47_oct_17.csv\u001b[m\u001b[m \u001b[31m5_apr_21.csv\u001b[m\u001b[m\n",
      "\u001b[31m22_nov_19.csv\u001b[m\u001b[m \u001b[31m35_oct_18.csv\u001b[m\u001b[m \u001b[31m48_sep_17.csv\u001b[m\u001b[m \u001b[31m60_sep_16.csv\u001b[m\u001b[m\n"
     ]
    }
   ],
   "source": [
    "#a list of all the files. a total of 6.958GB of unfiltered raw data. \n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0559f5e4-8774-41f1-947a-b9b2c94f70cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#using glob, to locate all file names. \n",
    "file_ext = '.csv'\n",
    "files = sorted([file for file in glob.glob(f'*{file_ext}')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9fbce328-28a8-4086-8f02-8992f4b70bed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first five files : ['10_nov_20.csv', '11_oct_20.csv', '12_sep_20.csv', '13_aug_20.csv', '14_jul_20.csv'] last 5 files:  ['6_mar_21.csv', '7_feb_21.csv', '8_jan_21.csv', '9_dec_20.csv']\n"
     ]
    }
   ],
   "source": [
    "#the first five in the list to confirm \n",
    "print('first five files :',files[0:5],\n",
    "      'last 5 files: ' ,files[-4:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb248bc2-7abd-4d55-853f-ee706ccca3a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fy/0gjwghjd3qxdc86mx10x01rr0000gp/T/ipykernel_1744/3199323081.py:2: DtypeWarning: Columns (23) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  all_flights = pd.concat([pd.read_csv(file) for file in files ])\n"
     ]
    }
   ],
   "source": [
    "#using the pd.concat() i will read from a list comprehension to concat each and every csv. \n",
    "all_flights = pd.concat([pd.read_csv(file) for file in files ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "36aba3bb-7f71-44c5-bcd2-5b152ecc708b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export to csv\n",
    "all_flights.to_csv( \"all_flights.csv\", index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "29f04e0e-39ed-455b-bd5b-7cdaebc8cb6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34409230, 34)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_flights.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b465c6-e5ea-4ea4-a2e6-c8bf2d806514",
   "metadata": {},
   "source": [
    "The process is completed with 34,409,230 flights with 34 _raw_ feature columns. It took approximately 8 minutes to process the file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "31dec8be-b05f-4d38-a00c-0bb93d5d11f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 34409230 entries, 0 to 371356\n",
      "Data columns (total 34 columns):\n",
      " #   Column               Dtype  \n",
      "---  ------               -----  \n",
      " 0   YEAR                 int64  \n",
      " 1   MONTH                int64  \n",
      " 2   DAY_OF_MONTH         int64  \n",
      " 3   DAY_OF_WEEK          int64  \n",
      " 4   FL_DATE              object \n",
      " 5   OP_UNIQUE_CARRIER    object \n",
      " 6   TAIL_NUM             object \n",
      " 7   OP_CARRIER_FL_NUM    int64  \n",
      " 8   ORIGIN               object \n",
      " 9   ORIGIN_CITY_NAME     object \n",
      " 10  ORIGIN_STATE_NM      object \n",
      " 11  DEST                 object \n",
      " 12  DEST_CITY_NAME       object \n",
      " 13  DEST_STATE_NM        object \n",
      " 14  CRS_DEP_TIME         int64  \n",
      " 15  DEP_TIME             float64\n",
      " 16  DEP_DELAY            float64\n",
      " 17  DEP_DELAY_NEW        float64\n",
      " 18  CRS_ARR_TIME         int64  \n",
      " 19  ARR_TIME             float64\n",
      " 20  ARR_DELAY            float64\n",
      " 21  ARR_DELAY_NEW        float64\n",
      " 22  CANCELLED            float64\n",
      " 23  CANCELLATION_CODE    object \n",
      " 24  DIVERTED             float64\n",
      " 25  CRS_ELAPSED_TIME     float64\n",
      " 26  FLIGHTS              float64\n",
      " 27  DISTANCE             float64\n",
      " 28  CARRIER_DELAY        float64\n",
      " 29  WEATHER_DELAY        float64\n",
      " 30  NAS_DELAY            float64\n",
      " 31  SECURITY_DELAY       float64\n",
      " 32  LATE_AIRCRAFT_DELAY  float64\n",
      " 33  Unnamed: 33          float64\n",
      "dtypes: float64(17), int64(7), object(10)\n",
      "memory usage: 9.0+ GB\n"
     ]
    }
   ],
   "source": [
    "all_flights.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d81220-921f-4a62-9a53-bf1dd8d535c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
